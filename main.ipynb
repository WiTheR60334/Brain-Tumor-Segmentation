{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "\n",
    "train_img_dir = \"./NPYcombined/\"\n",
    "train_mask_dir = \"./NPYmask/\"\n",
    "val_img_dir = \"./Validation/image/\"\n",
    "val_mask_dir = \"./Validation/mask/\"\n",
    "\n",
    "img_list = os.listdir(train_img_dir)\n",
    "msk_list = os.listdir(train_mask_dir)\n",
    "val_img_list = os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)\n",
    "print(img_list)\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(img_list)\n",
    "\n",
    "img_num = random.randint(0,num_images-1)\n",
    "test_img = np.load(train_img_dir+img_list[img_num])\n",
    "test_mask = np.load(train_mask_dir+msk_list[img_num])\n",
    "print(test_img.shape)\n",
    "print(img_list[img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1c')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2w')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_list):\n",
    "    images=[]\n",
    "    for i, image_name in enumerate(img_list):    \n",
    "        if (image_name.split('.')[1] == 'npy'):\n",
    "            image = np.load(img_dir+image_name)\n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    return(images)\n",
    "\n",
    "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
    "    L = len(img_list)\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            X = load_img(img_dir, img_list[batch_start:limit])\n",
    "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
    "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_img_datagen = imageLoader(train_img_dir, img_list, \n",
    "                                train_mask_dir, msk_list, batch_size)\n",
    "\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img=img[img_num]\n",
    "test_mask=msk[img_num]\n",
    "test_mask=np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1c')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2w')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\n",
    "import segmentation_models_3D as sm\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def categorical_focal_loss(alpha, gamma):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.keras.backend.clip(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true * alpha + (tf.keras.backend.ones_like(y_true) - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (tf.keras.backend.ones_like(y_true) - y_true) * (1 - y_pred)\n",
    "        fl = - alpha_t * tf.keras.backend.pow((tf.keras.backend.ones_like(y_true) - p_t), gamma) * tf.keras.backend.log(p_t)\n",
    "        return tf.keras.backend.sum(fl, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    focal = categorical_focal_loss(alpha=0.25, gamma=2.0)(y_true, y_pred)\n",
    "    return dice + focal\n",
    "\n",
    "project_dir = 'C:/Users/Romir/Desktop/Projects/BraTS/'\n",
    "os.chdir(project_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Dense, Flatten, Reshape, LayerNormalization\n",
    "\n",
    "kernel_initializer = 'he_uniform'\n",
    "\n",
    "def kan_layer(x, units):\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def tok_kan_block(x, filters):\n",
    "    x = Conv3D(filters, (1, 1, 1), padding='same')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = kan_layer(x, filters)\n",
    "    x = Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def U_KAN(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    #convultional layer with 16 filters, kernel size of 3x3x3, relu activation function and he_uniform kernel initializer , padding same to keep the same size of the image\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n",
    "    #dropout layer to prevent overfitting, which randomly sets 10% of the input units to 0 at each update during training time\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "    #maxpooling layer with pool size of 2x2x2 to reduce the size of the image by factor of 2,which downsamples the feature map, also helps in reducing the computational cost and prevent overfitting\n",
    "    p1 = MaxPooling3D((2, 2, 2), padding='same')(c1)\n",
    "    print(\"p1 shape:\", p1.shape)\n",
    "    \n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2), padding='same')(c2)\n",
    "    print(\"p2 shape:\", p2.shape)\n",
    "\n",
    "    c3 = tok_kan_block(p2, 64)\n",
    "    p3 = MaxPooling3D((2, 2, 2), padding='same')(c3)\n",
    "    print(\"p3 shape:\", p3.shape)\n",
    "     \n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2), padding='same')(c4)\n",
    "    print(\"p4 shape:\", p4.shape)\n",
    "\n",
    "    #deepest layer / bottleneck layer\n",
    "    c5 = tok_kan_block(p4, 256)\n",
    "    print(\"c5 shape:\", c5.shape)\n",
    "    \n",
    "    #Expansive path \n",
    "    #Tranpose convolutional layer / deconvolutional layer \n",
    "    #it upsamples the feature map by a factor of 2, which helps in increasing the size of the image\n",
    "    #Stride determines how much the window is moved in each step. A stride of 2 in each dimension doubles the spatial dimensions.\n",
    "    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    #helps to preserve spatial information lost during downsamplin by combining u6 and c4\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n",
    "    print(\"c6 shape:\", c6.shape)\n",
    "     \n",
    "    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n",
    "    print(\"c7 shape:\", c7.shape)\n",
    "\n",
    "    c7 = tok_kan_block(c7, 64)\n",
    "    print(\"tokenized c7 shape:\", c7.shape)\n",
    "     \n",
    "    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n",
    "    print(\"c8 shape:\", c8.shape)\n",
    "     \n",
    "    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n",
    "    print(\"c9 shape:\", c9.shape)\n",
    "     \n",
    "    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unet_3d_model import U_KAN\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_DEPTH = 128\n",
    "IMG_CHANNELS = 3\n",
    "num_classes = 4\n",
    "\n",
    "model = U_KAN(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy', sm.metrics.IOUScore(threshold=0.5)])\n",
    "\n",
    "steps_per_epoch = len(img_list) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_img_datagen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.save('brats_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "model = tf.keras.models.load_model('brats_1.h5', compile=False)\n",
    "\n",
    "model.compile(optimizer=optim, loss=combined_loss, metrics=metrics)\n",
    "\n",
    "loss, accuracy, iou_score = model.evaluate(train_img_datagen, steps=steps_per_epoch)\n",
    "print(f'Validation Loss: {loss}')\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "print(f'Validation IOU Score: {iou_score}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "my_model = load_model('brats_1.h5', \n",
    "                      custom_objects={'dice_loss_plus_1focal_loss': combined_loss,\n",
    "                                      'iou_score':sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "history2=my_model.fit(train_img_datagen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=1,\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('brats_1.h5', \n",
    "                      compile=False)\n",
    "\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "batch_size=4\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "test_pred_batch = my_model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 28\n",
    "\n",
    "test_img = np.load(\"C:/Users/Romir/Desktop/Projects/BraTS/Validation/image/image_\"+str(img_num)+\".npy\")\n",
    "\n",
    "test_mask = np.load(\"C:/Users/Romir/Desktop/Projects/BraTS/Validation/mask/mask_\"+str(img_num)+\".npy\")\n",
    "test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = my_model.predict(test_img_input)\n",
    "test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n",
    "\n",
    "\n",
    "# print(test_prediction_argmax.shape)\n",
    "# print(test_mask_argmax.shape)\n",
    "# print(np.unique(test_prediction_argmax))\n",
    "\n",
    "\n",
    "#Plot individual slices from test predictions for verification\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "n_slice=random.randint(0, test_prediction_argmax.shape[2])\n",
    "# n_slice = 50\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,n_slice,1], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask_argmax[:,:,n_slice])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction_argmax[:,:, n_slice])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
